# Notes de pr√©paration pour l'examen Anderson Fabian MOSQUERA VARELA

# Plan ‚Äú4 heures‚Äù (timing r√©aliste)
0:00 ‚Äì 0:15
Lire le sujet, lister livrables, cr√©er l‚Äôarborescence, lancer docker compose.
0:15 ‚Äì 1:05
Notebook exploration JSON + d√©cisions (sch√©ma, cleaning, cible ML).
1:05 ‚Äì 2:05
Scripts ETL + ORM + ingestion DB. V√©rif rapide dans phpMyAdmin.
2:05 ‚Äì 2:50
ML training + m√©triques + joblib.
2:50 ‚Äì 3:25
Kafka producer/consumer ‚Äúsimple‚Äù + d√©monstration (quelques messages).
3:25 ‚Äì 3:45
Tests pytest + robustesse ingestion.
3:45 ‚Äì 4:00
README synth√®se + zip final + dernier check.

# 1. pr√©parer les dossier de travails et les fichies √† g√©n√©rer.
selon l'information donn√©e pour la pr√©paration de l'examen une archicteture global du dossier du travail peut √™tre

```powershell
ExamenBloc2/
  README.md
  synthese.md
  requirements.txt
  docker-compose.yml
  .env
  notebooks/
    01_exploration.ipynb
  src/
    __init__.py
    config.py
    extract_transform.py
    db_models.py
    ingest.py
    train.py
    kafka_pipeline.py
    utils.py
  tests/
    test_ingestion.py
  data/            # s'il y a des fichiers data
    raw            # Dossier o√π on met le JSON brut
    processed      # Dossier o√π on met les donn√©es nettoy√©es
    features       # features pr√™tes pour le ML

  artifacts/       # Exemples : le mod√®le entra√Æn√© (model.pkl), un scaler (scaler.pkl), un encoder (onehot_encoder.pkl), un label encoder, des m√©triques (metrics.json), des hyperparam√®tres, la version du mod√®le, des logs d‚Äôentra√Ænement, etc.
  outputs/         # figures, rapports, logs
```

Note : 
```bash
Gr√¢ce √† __init__.py dans un dossier, par exemple src, Python autorise :
from src.config import RAW_JSONL_PATH
Sans __init__.py ‚ùå :
ModuleNotFoundError: No module named 'src'

Pour lancer depuis bash par exemple le script generate_data qui contient la ligne de code from src.config import RAW_JSONL_PATH
il est necessaire
python3 -m src.generate_data
‚úîÔ∏è Python comprend :
src est un package
generate_data est un module du package src
les imports from src.config import ... fonctionnent
```

Notes : 
```bash
# 1Ô∏è‚É£ Cr√©er un dossier
mkdir mon_dossier
# 2Ô∏è‚É£ Se d√©placer dans un dossier
cd mon_dossier
# 3Ô∏è‚É£ Cr√©er un fichier vide
touch fichier.txt
# 4Ô∏è‚É£ Cr√©er un fichier avec du texte
echo "Bonjour" > fichier.txt
# 5Ô∏è‚É£ Ajouter du texte √† la fin d'un fichier
echo "Nouvelle ligne" >> fichier.txt
# 6Ô∏è‚É£ Afficher le contenu d'un fichier
cat fichier.txt
# 7Ô∏è‚É£ Lister les fichiers d'un dossier
ls -l
# 8Ô∏è‚É£ Copier un fichier
cp fichier.txt copie.txt
# 9Ô∏è‚É£ D√©placer ou renommer un fichier
mv fichier.txt nouveau_nom.txt
# üîü Supprimer un fichier ou un dossier
rm nouveau_nom.txt       # fichier
rm -r mon_dossier        # dossier et son contenu
```

# 2. Pr√©parer l'environnement virtuelle avec les dependances qui seron √† utiliser  pendant l'examen
les commandes √† savoir pour ce partie sont : 
```bash
# Pr√©parer le fichier requierements.txt
# Partir du fichier requierements.txt fait pendant la pr√©paration de l'examen
```

```bash
# 1Ô∏è‚É£ Mettre √† jour le gestionnaire de paquets (optionnel, utile sur Linux)
sudo apt update
# 2Ô∏è‚É£ Cr√©er l'environnement virtuel Python nomm√© ".venv"
python3 -m venv .venv
# 3Ô∏è‚É£ Activer l'environnement virtuel
source .venv/bin/activate
# 4Ô∏è‚É£ Installer toutes les d√©pendances list√©es dans requirements.txt
pip install --upgrade pip  # Mettre pip √† jour avant installation
pip install -r requirements.txt
# 5Ô∏è‚É£ V√©rifier que les paquets sont bien install√©s
pip list
# 6Ô∏è‚É£ D√©sactiver l'environnement virtuel si n√©cessaire
deactivate

#Pour lancer des scripts : Exemple
python3 src/generate_data.py

#si le script est dans un dossier avec un fichier __init__.py, par exemple src avec ce fichier de dans, il est possible de faire
python3 -m src.generate_data
```

# 4. Pr√©parer le fichier .env qui va contenir les variables d'environnement qui vont √™tre utilis√©s par les scripts et par les fichier Docker .env
une proposition √† cr√©er unitioalment avec les variables que nous savons d√©j√† qu'allons utiliser dasn le docker-compose-yml sont :

```
# voir le .env
```

# 4. Pr√©parer le template du fichier docker-compose.yml avec les services n√©cessaires pour l‚Äô√©valuation.
ici un possible fichier docker-compose.yml avec les informations donn√©es pour pr√©parer l'√©valution
```yaml
# voir le docker-compose.yml
```

Pour lancer les services docker les commandes sont les suivantes
```bash
# -------------------------------------------------------------
# 1Ô∏è‚É£ Cr√©er les images (si n√©cessaire) et d√©marrer les services en arri√®re-plan
# -------------------------------------------------------------
docker compose up -d
# - "up" : construit les images si elles n'existent pas et d√©marre les conteneurs
# - "-d" : mode d√©tach√© (les conteneurs tournent en arri√®re-plan)
# -------------------------------------------------------------
# 2Ô∏è‚É£ Voir les conteneurs Docker en cours d'ex√©cution
# -------------------------------------------------------------
docker ps
# Affiche la liste des conteneurs actifs avec leurs ports, noms, et statuts
# -------------------------------------------------------------
# 3Ô∏è‚É£ Stopper un conteneur sp√©cifique
# -------------------------------------------------------------
docker stop <nom_du_conteneur>
# Exemple : docker stop exam-mysql
# -------------------------------------------------------------
# 4Ô∏è‚É£ Stopper tous les conteneurs
# -------------------------------------------------------------
docker stop $(docker ps -q)
# "$(docker ps -q)" r√©cup√®re tous les IDs des conteneurs en cours
# -------------------------------------------------------------
# 5Ô∏è‚É£ Supprimer un conteneur sp√©cifique
# -------------------------------------------------------------
docker rm <nom_du_conteneur>
# Exemple : docker rm exam-mysql
# Attention : le conteneur doit √™tre arr√™t√© avant de le supprimer
# -------------------------------------------------------------
# 6Ô∏è‚É£ Supprimer tous les conteneurs
# -------------------------------------------------------------
docker rm $(docker ps -a -q)
# "$(docker ps -a -q)" r√©cup√®re tous les IDs des conteneurs, m√™me arr√™t√©s
# -------------------------------------------------------------
# 7Ô∏è‚É£ Supprimer tous les volumes Docker
# -------------------------------------------------------------
docker volume rm $(docker volume ls -q)
# Attention : supprime toutes les donn√©es persistantes
# -------------------------------------------------------------
# 8Ô∏è‚É£ Red√©marrer les services (stop + up)
# -------------------------------------------------------------
docker compose down        # Arr√™te et supprime les conteneurs du compose
docker compose up -d       # Red√©marre les services
# -------------------------------------------------------------
# 9Ô∏è‚É£ Afficher les logs d‚Äôun service en temps r√©el
# -------------------------------------------------------------
docker compose logs -f <nom_service>
# Exemple : docker compose logs -f mysql
# "-f" = follow, pour voir les logs en continu
# -------------------------------------------------------------
# 10Ô∏è Inspecter l‚Äô√©tat d√©taill√© d‚Äôun conteneur
# -------------------------------------------------------------
docker inspect <nom_du_conteneur>
# Affiche toutes les informations du conteneur (r√©seau, volumes, configuration)
```
# Pour acc√©der aux interfaces depuis le navigateur
phpMyAdmin (interface web pour MySQL) ‚Üí http://localhost:8080
Kafka UI (interface web pour Kafka) ‚Üí http://localhost:8081

# 5. Pr√©parer le fichier config.py, √† partir duquel les script vont lire les variables necessaire pour travailler.
```yaml
# Voir le fichier de config.py de base pr√©par√© pr√©alablement
```

# 6. Faire l'analyse de donn√©es JSON dans le notebook
Il est n√©cessaire de s‚Äôassurer, avant tout, que le notebook s‚Äôex√©cute correctement avec le kernel de l‚Äôenvironnement virtuel
Avec l'environnement virtuel active, il faut creer le kernel de celui-ci

```bash
#activer l'environnement virtuel 
source .venv/bin/activate

#Para saber con cual python se esta trabajando
which python

# installer ipykernel que normalement est d√©j√† install√© √† partir du fichier requirements.txt
pip install ipykernel
pip install --upgrade ipykernel
pip install --upgrade jupyter


#Cr√©er un kernel Jupyter li√© √† l‚Äôenvironnement virtuel
python3 -m ipykernel install --user \
    --name ExamenBloc2 \
    --display-name "Python (.venv ExamenBloc2)"

#voir su le ipykerbel est bien cr√©√©
jupyter kernelspec list

#Pour ouvrir la terminar dans le navigateur
jupyter notebook

#supprimer les kernels inutils
jupyter kernelspec remove examenbloc2
Une page web s‚Äôouvre automatiquement (souvent : http://localhost:8888)

#V√©rifie avec une cellule pour assurer que j'ai les biblioteques qui sont dans l'enviroment virtuel:
import sys
print(sys.executable)
#Resultat attendu
/home/ubuntu/ExamenBloc2/.venv/bin/python

```
Une fois ce partie realise, il est possible de cr√©er le fichier .ipynb (exploration.ipynb) et selectionner le kernel qu'on vient de cr√©er. 


# Information sur git 

Quick setup ‚Äî if you‚Äôve done this kind of thing before
or	
https://github.com/epsf-a-mosquera/PreparationExamenBloc2.git
Get started by creating a new file or uploading an existing file. We recommend every repository include a README, LICENSE, and .gitignore.

‚Ä¶or create a new repository on the command line
echo "# PreparationExamenBloc2" >> README.md
git init
git add README.md
git add .
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/epsf-a-mosquera/PreparationExamenBloc2.git
git push -u origin main
‚Ä¶or push an existing repository from the command line
git remote add origin https://github.com/epsf-a-mosquera/PreparationExamenBloc2.git
git branch -M main
git push -u origin main


