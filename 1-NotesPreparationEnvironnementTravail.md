# Notes de pr√©paration pour l'examen Anderson Fabian MOSQUERA VARELA

# Plan ‚Äú4 heures‚Äù (timing r√©aliste)
0:00 ‚Äì 0:15
Lire le sujet, lister livrables, cr√©er l‚Äôarborescence, lancer docker compose.
0:15 ‚Äì 1:05
Notebook exploration JSON + d√©cisions (sch√©ma, cleaning, cible ML).
1:05 ‚Äì 2:05
Scripts ETL + ORM + ingestion DB. V√©rif rapide dans phpMyAdmin.
2:05 ‚Äì 2:50
ML training + m√©triques + joblib.
2:50 ‚Äì 3:25
Kafka producer/consumer ‚Äúsimple‚Äù + d√©monstration (quelques messages).
3:25 ‚Äì 3:45
Tests pytest + robustesse ingestion.
3:45 ‚Äì 4:00
README synth√®se + zip final + dernier check.

# 1. pr√©parer les dossier de travails et les fichies √† g√©n√©rer.
selon l'information donn√©e pour la pr√©paration de l'examen une archicteture global du dossier du travail peut √™tre

```powershell
ExamenBloc2/
  README.md
  synthese.md
  requirements.txt
  docker-compose.yml
  .env
  notebooks/
    exploration.ipynb
  src/
    __init__.py
    config.py
    extract_transform.py
    db_models.py
    ingest.py
    train.py
    kafka_producer.py
    kafka_consumer.py
    utils.py
  tests/
    test_ingestion.py
  data/            # s'il y a des fichiers data
    raw            # Dossier o√π on met le JSON brut
    processed      # Dossier o√π on met les donn√©es nettoy√©es
    features       # features pr√™tes pour le ML

  artifacts/       # Exemples : le mod√®le entra√Æn√© (model.pkl), un scaler (scaler.pkl), un encoder (onehot_encoder.pkl), un label encoder, des m√©triques (metrics.json), des hyperparam√®tres, la version du mod√®le, des logs d‚Äôentra√Ænement, etc.
  outputs/         # figures, rapports, logs
```

Note : 
```bash
Gr√¢ce √† __init__.py dans un dossier, par exemple src, Python autorise :
from src.config import RAW_JSONL_PATH
Sans __init__.py ‚ùå :
ModuleNotFoundError: No module named 'src'

Pour lancer depuis bash par exemple le script generate_data qui contient la ligne de code from src.config import RAW_JSONL_PATH
il est necessaire
python3 -m src.generate_data
‚úîÔ∏è Python comprend :
src est un package
generate_data est un module du package src
les imports from src.config import ... fonctionnent
```

Notes : 
```bash
# 1Ô∏è‚É£ Cr√©er un dossier
mkdir mon_dossier
# 2Ô∏è‚É£ Se d√©placer dans un dossier
cd mon_dossier
# 3Ô∏è‚É£ Cr√©er un fichier vide
touch fichier.txt
# 4Ô∏è‚É£ Cr√©er un fichier avec du texte
echo "Bonjour" > fichier.txt
# 5Ô∏è‚É£ Ajouter du texte √† la fin d'un fichier
echo "Nouvelle ligne" >> fichier.txt
# 6Ô∏è‚É£ Afficher le contenu d'un fichier
cat fichier.txt
# 7Ô∏è‚É£ Lister les fichiers d'un dossier
ls -l
# 8Ô∏è‚É£ Copier un fichier
cp fichier.txt copie.txt
# 9Ô∏è‚É£ D√©placer ou renommer un fichier
mv fichier.txt nouveau_nom.txt
# üîü Supprimer un fichier ou un dossier
rm nouveau_nom.txt       # fichier
rm -r mon_dossier        # dossier et son contenu
```

# 2. Pr√©parer l'environnement virtuelle avec les dependances qui seron √† utiliser  pendant l'examen
les commandes √† savoir pour ce partie sont : 
```bash
# Pr√©parer le fichier requierements.txt
# Partir du fichier requierements.txt fait pendant la pr√©paration de l'examen
```

```bash
# 1Ô∏è‚É£ Mettre √† jour le gestionnaire de paquets (optionnel, utile sur Linux)
sudo apt update
# 2Ô∏è‚É£ Cr√©er l'environnement virtuel Python nomm√© ".venv"
python3 -m venv .venv
# 3Ô∏è‚É£ Activer l'environnement virtuel
source .venv/bin/activate
# 4Ô∏è‚É£ Installer toutes les d√©pendances list√©es dans requirements.txt
pip install --upgrade pip  # Mettre pip √† jour avant installation
pip install -r requirements.txt
#pour d√©sinstaller les paquets si n√©cessaire une exemple
pip uninstall -y Kafka kafka kafka-python dotenv
# 5Ô∏è‚É£ V√©rifier que les paquets sont bien install√©s
pip list
# 6Ô∏è‚É£ D√©sactiver l'environnement virtuel si n√©cessaire
deactivate
# 7Ô∏è‚É£ Pour creer un nouveau fichier requirements.txt apr√®s avoir install√© des paquets
pip freeze > requirements.txt
```
```python
#Pour lancer des scripts : Exemple
python3 src/generate_data.py

#si le script est dans un dossier avec un fichier __init__.py, par exemple src avec ce fichier de dans, il est possible de faire
python3 -m src.generate_data (√† faire si on a des imports from src.config import ... dans generate_data.py)
```

# 4. Pr√©parer le fichier .env qui va contenir les variables d'environnement qui vont √™tre utilis√©s par les scripts et par les fichier Docker .env
une proposition √† cr√©er unitioalment avec les variables que nous savons d√©j√† qu'allons utiliser dasn le docker-compose-yml sont :

```
# voir le .env
```

# 4. Pr√©parer le template du fichier docker-compose.yml avec les services n√©cessaires pour l‚Äô√©valuation.
ici un possible fichier docker-compose.yml avec les informations donn√©es pour pr√©parer l'√©valution
```yaml
# voir le docker-compose.yml
```

Pour lancer les services docker les commandes sont les suivantes
```bash
# -------------------------------------------------------------
# 1Ô∏è‚É£ Cr√©er les images (si n√©cessaire) et d√©marrer les services en arri√®re-plan
# -------------------------------------------------------------
docker compose up -d
# - "up" : construit les images si elles n'existent pas et d√©marre les conteneurs
# - "-d" : mode d√©tach√© (les conteneurs tournent en arri√®re-plan)
# -------------------------------------------------------------
# 2Ô∏è‚É£ Voir les conteneurs Docker en cours d'ex√©cution
# -------------------------------------------------------------
docker ps
# Affiche la liste des conteneurs actifs avec leurs ports, noms, et statuts
# -------------------------------------------------------------
# 3Ô∏è‚É£ Stopper un conteneur sp√©cifique
# -------------------------------------------------------------
docker stop <nom_du_conteneur>
# Exemple : docker stop exam-mysql
# -------------------------------------------------------------
# 4Ô∏è‚É£ Stopper tous les conteneurs
# -------------------------------------------------------------
docker stop $(docker ps -q)
# "$(docker ps -q)" r√©cup√®re tous les IDs des conteneurs en cours
# -------------------------------------------------------------
# 5Ô∏è‚É£ Supprimer un conteneur sp√©cifique
# -------------------------------------------------------------
docker rm <nom_du_conteneur>
# Exemple : docker rm exam-mysql
# Attention : le conteneur doit √™tre arr√™t√© avant de le supprimer
# -------------------------------------------------------------
# 6Ô∏è‚É£ Supprimer tous les conteneurs
# -------------------------------------------------------------
docker rm $(docker ps -a -q)
# "$(docker ps -a -q)" r√©cup√®re tous les IDs des conteneurs, m√™me arr√™t√©s
# -------------------------------------------------------------
# 7Ô∏è‚É£ Supprimer tous les volumes Docker
# -------------------------------------------------------------
docker volume rm $(docker volume ls -q)
# Attention : supprime toutes les donn√©es persistantes
# -------------------------------------------------------------
# 8Ô∏è‚É£ Red√©marrer les services (stop + up)
# -------------------------------------------------------------
docker compose down        # Arr√™te et supprime les conteneurs du compose
docker compose up -d       # Red√©marre les services
# -------------------------------------------------------------
# 9Ô∏è‚É£ Afficher les logs d‚Äôun service en temps r√©el
# -------------------------------------------------------------
docker compose logs -f <nom_service>
# Exemple : docker compose logs -f mysql
# "-f" = follow, pour voir les logs en continu
# -------------------------------------------------------------
# 10Ô∏è Inspecter l‚Äô√©tat d√©taill√© d‚Äôun conteneur
# -------------------------------------------------------------
docker inspect <nom_du_conteneur>
# Affiche toutes les informations du conteneur (r√©seau, volumes, configuration)
# -------------------------------------------------------------
# 11 supprimer tous les conteneurs, images et volumes
# -------------------------------------------------------------
docker system prune -a --volumes
# Attention : supprime toutes les donn√©es persistantes et images non utilis√©es
# -------------------------------------------------------------
# verification que les ports sont bien expos√©s
docker ps --format "table {{.Names}}\t{{.Ports}}"

# si il n'est pas possible d'acceder aux services despuis le navigateur, utiliser un tunnel SSH avc la commande suivante
ssh -L 8080:localhost:8080 -L 8081:localhost:8081 ubuntu@<IP_VM>
# Remplacer <IP_VM> par l'adresse IP de la VM
# donc si par exemple ubuntu@ip-172-31-40-176 --> pour touver l'ip publique de la vm 
curl ifconfig.me
# exemple de resultat 34.251.2.21

#depuis la machine virtuelle 
ssh -i ~/keys/data_enginering_machine.pem \
  -L 8080:localhost:8080 \
  -L 8081:localhost:8081 \
  ubuntu@34.251.2.21

#√† lancer de power shelle del computador
ssh -i "C:\Users\a.mosquera\Dropbox\FormationDataEngineer\data_enginering_machine.pem" `
  -L 18080:127.0.0.1:8080 `
  -L 18081:127.0.0.1:8081 `
  ubuntu@34.251.2.21


ssh -i ~/keys/data_enginering_machine.pem \
  -L 8080:localhost:8080 \
  -L 8081:localhost:8081 \
  ubuntu@34.251.2.21

ssh -i examen-bloc2.pem \
  -L 8080:localhost:8080 \
  -L 8081:localhost:8081 \
  ubuntu@IP_PUBLIQUE

# pour √©viter le probl√®me de permission denied for key
chmod 600 ~/ExamenBloc2/keys/data_enginering_machine.pem

```

# installer dnas la VM un navigateur web l√©ger pour pouvoir acc√©der aux interfaces web des services docker
```bash
sudo apt update
sudo apt install -y firefox
```
# pour lancer firefox depuis la VM
```bash
firefox &
```
# pour verifier les ports expos√©s par les conteneurs docker
```bash
docker ps --format "table {{.Names}}\t{{.Ports}}"
```

# Pour acc√©der aux interfaces depuis le navigateur
phpMyAdmin (interface web pour MySQL) ‚Üí http://localhost:8080
Kafka UI (interface web pour Kafka) ‚Üí http://localhost:8081

# 5. Pr√©parer le fichier config.py, √† partir duquel les script vont lire les variables necessaire pour travailler.
```yaml
# Voir le fichier de config.py de base pr√©par√© pr√©alablement
```

# 6. Faire l'analyse de donn√©es JSON dans le notebook
Il est n√©cessaire de s‚Äôassurer, avant tout, que le notebook s‚Äôex√©cute correctement avec le kernel de l‚Äôenvironnement virtuel
Avec l'environnement virtuel active, il faut creer le kernel de celui-ci

```bash
#activer l'environnement virtuel 
source .venv/bin/activate

#Para saber con cual python se esta trabajando
which python

# installer ipykernel que normalement est d√©j√† install√© √† partir du fichier requirements.txt
pip install ipykernel
pip install --upgrade ipykernel
pip install --upgrade jupyter


#Cr√©er un kernel Jupyter li√© √† l‚Äôenvironnement virtuel
python3 -m ipykernel install --user \
    --name ExamenBloc2 \
    --display-name "Python (.venv ExamenBloc2)"

#voir su le ipykerbel est bien cr√©√©
jupyter kernelspec list

#Pour ouvrir la terminar dans le navigateur
jupyter notebook

#supprimer les kernels inutils
jupyter kernelspec remove examenbloc2
Une page web s‚Äôouvre automatiquement (souvent : http://localhost:8888)

#V√©rifie avec une cellule pour assurer que j'ai les biblioteques qui sont dans l'enviroment virtuel:
import sys
print(sys.executable)
#Resultat attendu
/home/ubuntu/ExamenBloc2/.venv/bin/python

```
Une fois ce partie realise, il est possible de cr√©er le fichier .ipynb (exploration.ipynb) et selectionner le kernel qu'on vient de cr√©er. 
on commence l'analyse des donn√©es JSON et la prise de d√©cisions pour la suite.


# Information sur git 

üìå Information sur Git
1Ô∏è‚É£ Initialiser un d√©p√¥t local
Si tu commences un projet depuis z√©ro :
# Cr√©e un fichier README
echo "# PreparationExamenBloc2" >> README.md
# Initialise le d√©p√¥t Git
git init
# Ajouter tous les fichiers du projet au suivi
git add .
# Faire le premier commit
git commit -m "first commit"
# Renommer la branche principale en 'main'
git branch -M main

2Ô∏è‚É£ Connecter le d√©p√¥t local √† un d√©p√¥t distant
# Ajouter l'URL du d√©p√¥t distant
git remote add origin https://github.com/epsf-a-mosquera/PreparationExamenBloc2.git
# Envoyer les commits locaux vers le d√©p√¥t distant (premier push)
git push -u origin main
Apr√®s le premier push, tu pourras utiliser simplement git push pour les futurs commits.
#forcer le push (si n√©cessaire)
git push origin nom_de_la_branche --force
git push origin main --force

3Ô∏è‚É£ Ajouter/modifier des fichiers et pousser les changements
# Ajouter un nouveau fichier ou les modifications
git add fichier_ou_dossier
# Faire un commit
git commit -m "Message d√©crivant les changements"
# Envoyer les changements au d√©p√¥t distant
git push

4Ô∏è‚É£ R√©cup√©rer un d√©p√¥t distant sur ta machine (VM ou autre)
Si tu veux travailler sur la VM et r√©cup√©rer le projet distant :
# Cloner le d√©p√¥t distant
git clone https://github.com/epsf-a-mosquera/PreparationExamenBloc2.git
# Se d√©placer dans le dossier clon√©
cd PreparationExamenBloc2
git clone cr√©e un dossier local avec tous les fichiers et l‚Äôhistorique Git.

5Ô∏è‚É£ Mettre √† jour ton d√©p√¥t local avec les changements du d√©p√¥t distant
# R√©cup√©rer les changements depuis le d√©p√¥t distant
git fetch
# Fusionner les changements dans la branche courante
git merge origin/main
Ou plus simple (commande courante) :
git pull
git pull = git fetch + git merge

6Ô∏è‚É£ V√©rifier l‚Äô√©tat du d√©p√¥t
# Voir les fichiers modifi√©s/non suivis
git status
# Voir l‚Äôhistorique des commits
git log --oneline --graph --all

7Ô∏è‚É£ Supprimer des fichiers ou dossiers du suivi
# Retirer un fichier du suivi Git mais le garder sur le disque
git rm --cached fichier.txt
# Retirer un dossier entier du suivi
git rm -r --cached dossier/
Pratique pour .venv/ ou data/ apr√®s avoir ajout√© un .gitignore.

